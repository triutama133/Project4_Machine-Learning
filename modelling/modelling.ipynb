{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data type has been saved...\n",
      "Preprocessing data amount has been saved...\n",
      "Preprocessing data oldbalanceOrg has been saved...\n",
      "Preprocessing data newbalanceOrig has been saved...\n",
      "Preprocessing data oldbalanceDest has been saved...\n",
      "Preprocessing data newbalanceDest has been saved...\n",
      "Training model done in 0.03306770324707031 seconds...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def prepOneHotEncoder(df, col, pathPackages):\n",
    "    oneHotEncoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    dfOneHotEncoder = pd.DataFrame(oneHotEncoder.fit_transform(df[[col]]).toarray(),\n",
    "                                   columns=[col + \"_\" + str(i+1) for i in range(len(df[col].unique()))])\n",
    "    \n",
    "    filename = 'prep' + col + '.pkl'\n",
    "    # Use os.path.join for the path\n",
    "    pickle.dump(oneHotEncoder, open(os.path.join(pathPackages, filename), 'wb'))\n",
    "    print(f\"Preprocessing data {col} has been saved...\")\n",
    "    \n",
    "    df = pd.concat([df.drop(col, axis=1), dfOneHotEncoder], axis=1)\n",
    "    return df\n",
    "\n",
    "def prepStandardScaler(df, col, pathPackages):\n",
    "    scaler = StandardScaler()\n",
    "    df[col] = scaler.fit_transform(df[[col]])\n",
    "    \n",
    "    filename = 'prep' + col + '.pkl'\n",
    "    # Use os.path.join for the path\n",
    "    pickle.dump(scaler, open(os.path.join(pathPackages, filename), 'wb'))\n",
    "    print(f\"Preprocessing data {col} has been saved...\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def runModel(data, path):\n",
    "    # Use os.path.join for the path\n",
    "    path = os.path.join(path, \"modelling\", \"packages\")\n",
    "    col = pickle.load(open(os.path.join(path, 'columnModelling.pkl'), 'rb'))\n",
    "    df = pd.DataFrame(data, index=[0])\n",
    "    df = df[col]\n",
    "\n",
    "    prepType = pickle.load(open(os.path.join(path, 'preptype.pkl'), 'rb'))\n",
    "    dfType = pd.DataFrame(prepType.transform(df[['type']]).toarray(),\n",
    "                          columns=[\"type_\" + str(i+1) for i in range(len(prepType.transform(df[['type']]).toarray()[0]))])\n",
    "    df = pd.concat([df.drop('type', axis=1), dfType], axis=1)\n",
    "\n",
    "    X = df.values.tolist()\n",
    "    model = pickle.load(open(os.path.join(path, 'modelFraud.pkl'), 'rb'))\n",
    "    y = model.predict(X)[0]\n",
    "    if y == 0:\n",
    "        return \"White List\"\n",
    "    else:\n",
    "        return \"Fraud\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Correct the path to use os.path.join\n",
    "    pathPackages = os.path.join(os.getcwd(), \"packages\")\n",
    "    target = 'isFraud'\n",
    "    \n",
    "    # Use os.path.join for the path\n",
    "    data = pd.read_csv(os.path.join(pathPackages, 'Fraud_Detection.csv'))\n",
    "    data = data.drop(['nameOrig', 'nameDest'], axis=1)\n",
    "    \n",
    "    df = data.drop(target, axis=1)\n",
    "    # Use os.path.join for the path\n",
    "    pickle.dump(df.columns.tolist(), open(os.path.join(pathPackages, 'columnModelling.pkl'), 'wb'))\n",
    "\n",
    "    colOneHotEncoder = ['type']\n",
    "    for col in colOneHotEncoder:\n",
    "        df = prepOneHotEncoder(df, col, pathPackages)\n",
    "\n",
    "    colprepStandardScaler = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "    for col in colprepStandardScaler:\n",
    "        df = prepStandardScaler(df, col, pathPackages)\n",
    "\n",
    "    X = df.values.tolist()\n",
    "    y = data[[target]].values.ravel()\n",
    "    \n",
    "    start = time.time()\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    stop = time.time()\n",
    "    \n",
    "    # Use os.path.join for the path\n",
    "    with open(os.path.join(pathPackages, 'modelFraud.pkl'), 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    print(f\"Training model done in {stop-start} seconds...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/trianka-utama/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/trianka-utama/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/trianka-utama/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/trianka-utama/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/trianka-utama/.config/jupyterlab-desktop/jlab_server/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
